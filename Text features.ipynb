{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "Collecting nltk>=3.8\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (4.50.2)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (0.17.0)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2024.7.24-cp38-cp38-win_amd64.whl (269 kB)\n",
      "Installing collected packages: regex, nltk, textblob\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2020.10.15\n",
      "    Uninstalling regex-2020.10.15:\n",
      "      Successfully uninstalled regex-2020.10.15\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.5\n",
      "    Uninstalling nltk-3.5:\n",
      "      Successfully uninstalled nltk-3.5\n",
      "Successfully installed nltk-3.9.1 regex-2024.7.24 textblob-0.18.0.post0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   exclamation_marks  question_marks  capitalized_words  sentiment_polarity  \\\n",
      "0                  0               0                  0            0.000000   \n",
      "1                  0               0                  0            0.200000   \n",
      "2                  0               0                  0            0.129167   \n",
      "3                  2               0                  3            0.000000   \n",
      "4                  0               0                  0            0.386667   \n",
      "\n",
      "   sentiment_subjectivity  punctuation_count  \n",
      "0                   0.000                  1  \n",
      "1                   0.200                  4  \n",
      "2                   0.525                  3  \n",
      "3                   0.550                 15  \n",
      "4                   0.360                  8  \n",
      "    00  000   01  017   03  032g   04   06  064g   08  ...  zte  ztpad  zumo  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  ...  0.0    0.0   0.0   \n",
      "1  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  ...  0.0    0.0   0.0   \n",
      "2  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  ...  0.0    0.0   0.0   \n",
      "3  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  ...  0.0    0.0   0.0   \n",
      "4  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  ...  0.0    0.0   0.0   \n",
      "\n",
      "   zune  exclamation_marks  question_marks  capitalized_words  \\\n",
      "0   0.0                  0               0                  0   \n",
      "1   0.0                  0               0                  0   \n",
      "2   0.0                  0               0                  0   \n",
      "3   0.0                  2               0                  3   \n",
      "4   0.0                  0               0                  0   \n",
      "\n",
      "   sentiment_polarity  sentiment_subjectivity  punctuation_count  \n",
      "0            0.000000                   0.000                  1  \n",
      "1            0.200000                   0.200                  4  \n",
      "2            0.129167                   0.525                  3  \n",
      "3            0.000000                   0.550                 15  \n",
      "4            0.386667                   0.360                  8  \n",
      "\n",
      "[5 rows x 5006 columns]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.70      0.42      0.53        50\n",
      "         2.0       0.00      0.00      0.00        20\n",
      "         3.0       0.00      0.00      0.00        25\n",
      "         4.0       0.00      0.00      0.00       106\n",
      "         5.0       0.82      1.00      0.90       782\n",
      "\n",
      "    accuracy                           0.81       983\n",
      "   macro avg       0.30      0.28      0.29       983\n",
      "weighted avg       0.69      0.81      0.74       983\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'amazon_review.csv'  # Using file path Locally\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure that the 'reviewText' column is in string format\n",
    "data['reviewText'] = data['reviewText'].astype(str)\n",
    "\n",
    "# Feature 1: Count of Exclamation Marks\n",
    "data['exclamation_marks'] = data['reviewText'].apply(lambda x: x.count('!'))\n",
    "\n",
    "# Feature 2: Count of Question Marks\n",
    "data['question_marks'] = data['reviewText'].apply(lambda x: x.count('?'))\n",
    "\n",
    "# Feature 3: Count of Capitalized Words\n",
    "def count_capitalized_words(text):\n",
    "    return sum(1 for word in text.split() if word.isupper() and len(word) > 1)\n",
    "\n",
    "data['capitalized_words'] = data['reviewText'].apply(count_capitalized_words)\n",
    "\n",
    "# Feature 4: Sentiment Polarity (using TextBlob)\n",
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "data['sentiment_polarity'] = data['reviewText'].apply(get_sentiment)\n",
    "\n",
    "# Feature 5: Sentiment Subjectivity (using TextBlob)\n",
    "def get_subjectivity(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.subjectivity\n",
    "\n",
    "data['sentiment_subjectivity'] = data['reviewText'].apply(get_subjectivity)\n",
    "\n",
    "# Feature 6: Count of Punctuation (total punctuation marks)\n",
    "def count_punctuation(text):\n",
    "    return len([char for char in text if char in string.punctuation])\n",
    "\n",
    "data['punctuation_count'] = data['reviewText'].apply(count_punctuation)\n",
    "\n",
    "# Display the new features\n",
    "print(data[['exclamation_marks', 'question_marks', 'capitalized_words', 'sentiment_polarity', 'sentiment_subjectivity', 'punctuation_count']].head())\n",
    "\n",
    "# TF-IDF Feature Extraction (Combining with New Features)\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "tfidf_matrix = tfidf.fit_transform(data['reviewText'])\n",
    "\n",
    "# Convert the TF-IDF matrix into a DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names())  # Using get_feature_names() for older Scikit-learn versions\n",
    "\n",
    "# Combine the new text features with the TF-IDF matrix\n",
    "combined_features = pd.concat([tfidf_df, data[['exclamation_marks', 'question_marks', 'capitalized_words', 'sentiment_polarity', 'sentiment_subjectivity', 'punctuation_count']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Show combined features\n",
    "print(combined_features.head())\n",
    "\n",
    "# Now, you can use 'combined_features' as input for model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming 'overall' is the target variable\n",
    "X = combined_features\n",
    "y = data['overall']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
